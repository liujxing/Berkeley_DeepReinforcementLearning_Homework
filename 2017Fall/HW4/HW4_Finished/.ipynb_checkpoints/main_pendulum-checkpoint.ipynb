{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import logz\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normc_initializer(std=1.0):\n",
    "    \"\"\"\n",
    "    Initialize array with normalized columns. Each column has standard deviation of input std.\n",
    "    \"\"\"\n",
    "    def _initializer(shape, dtype=None, partition_info=None): #pylint: disable=W0613\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        return tf.constant(out)\n",
    "    return _initializer\n",
    "\n",
    "def dense(x, size, name, weight_init=None):\n",
    "    \"\"\"\n",
    "    Dense (fully connected) layer\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(name + \"/w\", [x.get_shape()[1], size], initializer=weight_init)\n",
    "    b = tf.get_variable(name + \"/b\", [size], initializer=tf.zeros_initializer())\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "def fancy_slice_2d(X, inds0, inds1):\n",
    "    \"\"\"\n",
    "    Like numpy's X[inds0, inds1]. Here inds0 are the row indices and inds1 are the column indices.\n",
    "    The array selects X[inds0[i], inds1[i]] for i in range(len(inds0))\n",
    "    \"\"\"\n",
    "    inds0 = tf.cast(inds0, tf.int64)\n",
    "    inds1 = tf.cast(inds1, tf.int64)\n",
    "    shape = tf.cast(tf.shape(X), tf.int64)\n",
    "    ncols = shape[1]\n",
    "    Xflat = tf.reshape(X, [-1])\n",
    "    return tf.gather(Xflat, inds0 * ncols + inds1)\n",
    "\n",
    "def discount(x, gamma):\n",
    "    \"\"\"\n",
    "    Compute discounted sum of future values\n",
    "    out[i] = in[i] + gamma * in[i+1] + gamma^2 * in[i+2] + ...\n",
    "    \"\"\"\n",
    "    return scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]\n",
    "\n",
    "def explained_variance_1d(ypred,y):\n",
    "    \"\"\"\n",
    "    1 - Var[ypred - y] / var[y]. \n",
    "    https://www.quora.com/What-is-the-meaning-proportion-of-variance-explained-in-linear-regression\n",
    "    \"\"\"\n",
    "    assert y.ndim == 1 and ypred.ndim == 1    \n",
    "    vary = np.var(y)\n",
    "    return np.nan if vary==0 else 1 - np.var(y-ypred)/vary\n",
    "\n",
    "\n",
    "def categorical_sample_logits(logits): \n",
    "    \"\"\"   \n",
    "    Samples (symbolically) from categorical distribution using logits, where logits is a NxK\n",
    "    matrix specifying N categorical distributions with K categories\n",
    "\n",
    "    specifically, exp(logits) / sum( exp(logits), axis=1 ) is the \n",
    "    probabilities of the different classes\n",
    "\n",
    "    Cleverly uses gumbell trick, based on\n",
    "    https://github.com/tensorflow/tensorflow/issues/456\n",
    "    \"\"\"\n",
    "    U = tf.random_uniform(tf.shape(logits))\n",
    "    return tf.argmax(logits - tf.log(-tf.log(U)), dimension=1)\n",
    "\n",
    "def pathlength(path):\n",
    "    return len(path[\"reward\"])\n",
    "\n",
    "class LinearValueFunction(object):\n",
    "    \"\"\"\n",
    "    A class used to calculate state value function from linear function\n",
    "    \"\"\"\n",
    "    coef = None\n",
    "    def fit(self, X, y):\n",
    "        Xp = self.preproc(X)\n",
    "        A = Xp.T.dot(Xp)\n",
    "        nfeats = Xp.shape[1]\n",
    "        A[np.arange(nfeats), np.arange(nfeats)] += 1e-3 # a little ridge regression by adding a small value to the diagonal\n",
    "        b = Xp.T.dot(y)\n",
    "        self.coef = np.linalg.solve(A, b) # solve the linear regression slope\n",
    "    def predict(self, X):\n",
    "        if self.coef is None:\n",
    "            return np.zeros(X.shape[0])\n",
    "        else:\n",
    "            return self.preproc(X).dot(self.coef)\n",
    "    def preproc(self, X):\n",
    "        # transform X by including features of X**0, X**1, X**2\n",
    "        return np.concatenate([np.ones([X.shape[0], 1]), X, np.square(X)/2.0], axis=1)\n",
    "    \n",
    "      \n",
    "def lrelu(x, leak=0.2):\n",
    "    \"\"\"\n",
    "    Leaky Relu activation function\n",
    "    \"\"\"\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * abs(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NnValueFunction(object):\n",
    "    \"\"\"\n",
    "    A class used to calculate state value function from neural network\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, ob_dim, **vf_params):\n",
    "        self.trained = False\n",
    "        self.ob_dim = ob_dim\n",
    "        if \"n_epochs\" in vf_params:\n",
    "            self.n_epochs = vf_params[\"n_epochs\"]\n",
    "        else:\n",
    "            self.n_epochs = 10\n",
    "            \n",
    "        if \"stepsize\" in vf_params:\n",
    "            self.stepsize = vf_params[\"stepsize\"]\n",
    "        else:\n",
    "            self.stepsize = 1e-3\n",
    "            \n",
    "        # define an network mapping state to advantage function\n",
    "        self.sy_input_vf = tf.placeholder(shape=[None, self.ob_dim], name=\"VF_input\", dtype=tf.float32)\n",
    "        sy_h1_vf = lrelu(dense(self.sy_input_vf, 32, \"VF_h1\", weight_init=normc_initializer(1.0)))\n",
    "        self.sy_output_vf = tf.squeeze(dense(sy_h1_vf, 1, \"VF_output\", weight_init=normc_initializer(0.1)), squeeze_dims=1)\n",
    "        self.sy_target_vf = tf.placeholder(shape=[None], name=\"VF_target\", dtype=tf.float32)\n",
    "        self.loss = tf.reduce_sum(self.sy_output_vf-self.sy_target_vf)**2 / tf.to_float(tf.shape(self.sy_output_vf))\n",
    "        self.sy_stepsize = tf.placeholder(shape=[], dtype=tf.float32)\n",
    "        self.update_op = tf.train.AdamOptimizer(self.sy_stepsize).minimize(self.loss)\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.__enter__()\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trained = True\n",
    "        for i in range(self.n_epochs):\n",
    "            self.sess.run(self.update_op, feed_dict={self.sy_stepsize:self.stepsize, \n",
    "                                                     self.sy_input_vf:X,\n",
    "                                                     self.sy_target_vf:y})       \n",
    "        \n",
    "    def predict(self, X):\n",
    "        if not self.trained:\n",
    "            return np.zeros(X.shape[0])\n",
    "        else:\n",
    "            return self.sess.run(self.sy_output_vf, feed_dict={self.sy_input_vf:X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.sess.run(tf.shape(vf.loss), feed_dict={vf.sy_input_vf:})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03288476, -0.04454733, -0.05296792, ..., -0.35800251,\n",
       "       -0.39709851, -0.40172687], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.sess.run(vf.sy_output_vf, feed_dict={vf.sy_input_vf:ob_no})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vf.fit(ob_no, vtarg_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**main_pendulum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logdir=None\n",
    "seed=0\n",
    "n_iter=100 \n",
    "gamma=1.0\n",
    "min_timesteps_per_batch=1000\n",
    "initial_stepsize=1e-2\n",
    "desired_kl = 1.0\n",
    "#vf_type=\"linear\"\n",
    "#vf_params={}\n",
    "vf_type = \"nn\"\n",
    "vf_params = dict(n_epochs=10, stepsize=1e-3)\n",
    "animate=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-23 14:04:26,981] Making new env: Pendulum-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure_output_dir: not storing the git diff, probably because you're not in a git repo\n",
      "\u001b[32;1mLogging data to /tmp/experiments/1492970667/log.txt\u001b[0m\n",
      "WARNING:tensorflow:From <ipython-input-3-d210ff94295f>:29: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-23 14:04:27,592] From <ipython-input-3-d210ff94295f>:29: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "env = gym.make(\"Pendulum-v0\")\n",
    "ob_dim = env.observation_space.shape[0]\n",
    "ac_dim = env.action_space.shape[0]\n",
    "logz.configure_output_dir(logdir)\n",
    "if vf_type == 'linear':\n",
    "    vf = LinearValueFunction(**vf_params)\n",
    "elif vf_type == 'nn':\n",
    "    vf = NnValueFunction(ob_dim=ob_dim, **vf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KL divergence of two univariate normal distribution is\n",
    "\n",
    "$$KL[N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)] = log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2+(\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}$$\n",
    "\n",
    "For two multivariate normal distribution, the KL divergence is\n",
    "\n",
    "$$KL[N(\\mu_1, \\Sigma_1), N(\\mu_2, \\Sigma_2)] = \\frac{1}{2}[log\\frac{\\Sigma_2}{\\Sigma_1} - d + tr(\\Sigma_2^{-1}\\Sigma_1) + (\\mu_2 - \\mu_1)\\Sigma_2^{-1}(\\mu_2-\\mu_1)]$$\n",
    "\n",
    "If the two normal distribution are independent each across their dimensions, then the KL divergence of the full distribution is the sum of KL divergence of each dimension.\n",
    "\n",
    "The entropy of normal distribution $N(\\mu, \\sigma^2)$ is\n",
    "$$ S = log(\\sigma \\sqrt{2 \\pi e}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR_CODE_HERE\n",
    "\n",
    "sy_ob_no = tf.placeholder(shape=[None, ob_dim], name=\"ob\", dtype=tf.float32) # batch of observations\n",
    "sy_ac_n = tf.placeholder(shape=[None, ac_dim], name=\"ac\", dtype=tf.float32) # batch of actions taken by the policy, used for policy gradient computation\n",
    "sy_adv_n = tf.placeholder(shape=[None], name=\"adv\", dtype=tf.float32) # advantage function estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a network mapping state to probability of action\n",
    "sy_h1 = lrelu(dense(sy_ob_no, 32, \"h1\", weight_init=normc_initializer(1.0))) # hidden layer\n",
    "sy_mean_na = dense(sy_h1, ac_dim, \"mean\", weight_init=normc_initializer(0.1)) # mean output\n",
    "sy_logstd_a = tf.get_variable(\"logstdev\", [ac_dim], initializer=tf.zeros_initializer()) # log std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample the action anc calculate its log probability\n",
    "U = tf.random_normal([tf.shape(sy_ob_no)[0], ac_dim], 0.0, 1.0) # a number from standard normal distribution\n",
    "sy_sampled_ac = (U * tf.exp(sy_logstd_a) + sy_mean_na)[0] # convert standard normal to normal with given mean and var, used to update state and not for policy gradient\n",
    "#sy_logprob_n = -(sy_ac_n - sy_mean_na)**2/tf.exp(2*sy_logstd_a) - tf.log(2*np.pi)/2 - sy_logstd_a\n",
    "sy_logprob_n = tf.reduce_sum(-(sy_ac_n - sy_mean_na)**2/tf.exp(2*sy_logstd_a)/2 - sy_logstd_a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following quantities are just used for computing KL and entropy, JUST FOR DIAGNOSTIC PURPOSES >>>>\n",
    "sy_oldmean_na = tf.placeholder(shape=[None, ac_dim], name=\"oldmean\", dtype=tf.float32) # mean before update\n",
    "sy_oldlogstd_na = tf.placeholder(shape=[ac_dim], name=\"oldstd\", dtype=tf.float32) # std before update\n",
    "sy_n = tf.shape(sy_ob_no)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KL divergence\n",
    "sy_kl = tf.reduce_sum(sy_logstd_a-sy_oldlogstd_na - 0.5 + (tf.exp(sy_oldlogstd_na*2) + (sy_mean_na - \\\n",
    "                                 sy_oldmean_na)**2)/(2*tf.exp(sy_logstd_a*2))) / tf.to_float(sy_n)\n",
    "# entropy\n",
    "sy_ent = tf.reduce_sum(sy_logstd_a + 0.5 * tf.log(2*np.pi*np.e)) / tf.to_float(sy_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# end of your code\n",
    "\n",
    "sy_surr = - tf.reduce_mean(sy_adv_n * sy_logprob_n) # Loss function that we'll differentiate to get the policy gradient \n",
    "\n",
    "sy_stepsize = tf.placeholder(shape=[], dtype=tf.float32) # Symbolic, in case you want to change the stepsize during optimization. (We're not doing that currently)\n",
    "update_op = tf.train.AdamOptimizer(sy_stepsize).minimize(sy_surr)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.__enter__() # equivalent to `with sess:`\n",
    "tf.global_variables_initializer().run() #pylint: disable=E1101\n",
    "\n",
    "total_timesteps = 0\n",
    "stepsize = initial_stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 0 ************\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"********** Iteration %i ************\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR_CODE_HERE\n",
    "\n",
    "# Collect paths until we have enough timesteps\n",
    "timesteps_this_batch = 0\n",
    "paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    ob = env.reset()\n",
    "    terminated = False\n",
    "    obs, acs, rewards = [], [], []\n",
    "    animate_this_episode=(len(paths)==0 and (i % 10 == 0) and animate)\n",
    "    while True:\n",
    "        if animate_this_episode:\n",
    "            env.render()\n",
    "        obs.append(ob)\n",
    "        ac = sess.run(sy_sampled_ac, feed_dict={sy_ob_no : ob[None]})\n",
    "        acs.append(ac)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rewards.append(rew)\n",
    "        if done:\n",
    "            break                    \n",
    "    path = {\"observation\" : np.array(obs), \"terminated\" : terminated,\n",
    "            \"reward\" : np.array(rewards), \"action\" : np.array(acs)}\n",
    "    paths.append(path)\n",
    "    timesteps_this_batch += pathlength(path)\n",
    "    if timesteps_this_batch > min_timesteps_per_batch:\n",
    "        break\n",
    "total_timesteps += timesteps_this_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate advantage function\n",
    "vtargs, vpreds, advs = [], [], []\n",
    "for path in paths:\n",
    "    rew_t = path[\"reward\"]\n",
    "    return_t = discount(rew_t, gamma)\n",
    "    vpred_t = vf.predict(path[\"observation\"])\n",
    "    adv_t = return_t - vpred_t\n",
    "    advs.append(adv_t)\n",
    "    vtargs.append(return_t)\n",
    "    vpreds.append(vpred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build arrays for policy update\n",
    "ob_no = np.concatenate([path[\"observation\"] for path in paths])\n",
    "ac_n = np.concatenate([path[\"action\"] for path in paths])\n",
    "adv_n = np.concatenate(advs)\n",
    "standardized_adv_n = (adv_n - adv_n.mean()) / (adv_n.std() + 1e-8)\n",
    "vtarg_n = np.concatenate(vtargs)\n",
    "vpred_n = np.concatenate(vpreds)\n",
    "vf.fit(ob_no, vtarg_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Policy update\n",
    "_, old_mean_na, old_logstd_na = sess.run([update_op, sy_mean_na, sy_logstd_a], feed_dict={sy_ob_no:ob_no, sy_ac_n:ac_n, sy_adv_n:standardized_adv_n, sy_stepsize:stepsize})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kl, ent = sess.run([sy_kl, sy_ent], feed_dict={sy_ob_no:ob_no, sy_oldmean_na:old_mean_na, \n",
    "                                              sy_oldlogstd_na:old_logstd_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stepsize -> 0.015\n"
     ]
    }
   ],
   "source": [
    "# end of your code\n",
    "\n",
    "if kl > desired_kl * 2: \n",
    "    stepsize /= 1.5\n",
    "    print('stepsize -> %s'%stepsize)\n",
    "elif kl < desired_kl / 2: \n",
    "    stepsize *= 1.5\n",
    "    print('stepsize -> %s'%stepsize)\n",
    "else:\n",
    "    print('stepsize OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-99543250f918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EVBefore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplained_variance_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvpred_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtarg_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlogz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EVAfter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplained_variance_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtarg_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlogz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TimestepsSoFar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# If you're overfitting, EVAfter will be way larger than EVBefore.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e5140524b9da>\u001b[0m in \u001b[0;36mexplained_variance_1d\u001b[0;34m(ypred, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mWhat\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32mis\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthe\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmeaning\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mexplained\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mvary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvary\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "# Log diagnostics\n",
    "logz.log_tabular(\"EpRewMean\", np.mean([path[\"reward\"].sum() for path in paths]))\n",
    "logz.log_tabular(\"EpLenMean\", np.mean([pathlength(path) for path in paths]))\n",
    "logz.log_tabular(\"KLOldNew\", kl)\n",
    "logz.log_tabular(\"Entropy\", ent)\n",
    "logz.log_tabular(\"EVBefore\", explained_variance_1d(vpred_n, vtarg_n))\n",
    "logz.log_tabular(\"EVAfter\", explained_variance_1d(vf.predict(ob_no), vtarg_n))\n",
    "logz.log_tabular(\"TimestepsSoFar\", total_timesteps)\n",
    "# If you're overfitting, EVAfter will be way larger than EVBefore.\n",
    "# Note that we fit value function AFTER using it to compute the advantage function to avoid introducing bias\n",
    "logz.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vf.sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vf.predict(ob_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtarg_n.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
